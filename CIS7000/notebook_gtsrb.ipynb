{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoisonedDataset(Dataset):\n",
    "    def __init__(self, data, targets, pattern, weight, y_target, poison_rate, device):\n",
    "        self.classes = targets.unique().tolist()\n",
    "        self.data, self.targets = self._poison(data, targets, pattern, weight, y_target, poison_rate)\n",
    "        self.device = device\n",
    "\n",
    "    def _poison(self, data, targets, pattern, weight, y_target, poison_rate):\n",
    "        for i in np.random.choice(range(len(data)), size=int(len(data) * poison_rate), replace=False):\n",
    "            data[i] = data[i] * (1 - weight) + pattern * weight\n",
    "            targets[i] = y_target\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i].to(self.device), self.targets[i].to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(train_data, train_targets, test_data, test_targets, pattern, weight, y_target, poison_rate, batch_size):\n",
    "    train_poisoned_dataset = PoisonedDataset(\n",
    "        data=train_data.clone(),\n",
    "        targets=train_targets.clone(),\n",
    "        pattern=pattern,\n",
    "        weight=weight,\n",
    "        y_target=y_target,\n",
    "        poison_rate=poison_rate / 100,\n",
    "        device=device\n",
    "    )\n",
    "    test_original_dataset = PoisonedDataset(\n",
    "        data=test_data.clone(),\n",
    "        targets=test_targets.clone(),\n",
    "        pattern=pattern,\n",
    "        weight=weight,\n",
    "        y_target=y_target,\n",
    "        poison_rate=0,\n",
    "        device=device\n",
    "    )\n",
    "    test_poisoned_dataset = PoisonedDataset(\n",
    "        data=test_data.clone(),\n",
    "        targets=test_targets.clone(),\n",
    "        pattern=pattern,\n",
    "        weight=weight,\n",
    "        y_target=y_target,\n",
    "        poison_rate=1,\n",
    "        device=device\n",
    "    )\n",
    "    train_poisoned_dataloader = DataLoader(train_poisoned_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_original_dataloader = DataLoader(test_original_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_poisoned_dataloader = DataLoader(test_poisoned_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_poisoned_dataloader, test_original_dataloader, test_poisoned_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = torchvision.models.resnet18()\n",
    "    model.fc = nn.Linear(512, 43)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, print_classification_report=False):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for inputs, targets in dataloader:\n",
    "        y_true.append(targets)\n",
    "        y_pred.append(torch.argmax(model(inputs), dim=1))\n",
    "        \n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "    \n",
    "    if print_classification_report:\n",
    "        print(metrics.classification_report(y_true.cpu(), y_pred.cpu()))\n",
    "\n",
    "    return metrics.accuracy_score(y_true.cpu(), y_pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_poisoned_dataloader,\n",
    "    test_original_dataloader,\n",
    "    test_poisoned_dataloader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    model_save_path,\n",
    "    logs_save_path,\n",
    "    save_every_epoch\n",
    "):\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        for inputs, targets in tqdm(train_poisoned_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "\n",
    "        accuracy_train = evaluate(model, train_poisoned_dataloader)\n",
    "        accuracy_test_original = evaluate(model, test_original_dataloader)\n",
    "        accuracy_test_poisoned = evaluate(model, test_poisoned_dataloader)\n",
    "        logs.append((epoch, running_loss.item(), accuracy_train, accuracy_test_original, accuracy_test_poisoned))\n",
    "\n",
    "        print(f\"Epoch: {epoch:02d}   Loss: {running_loss.item():.4f}    Train Acc: {accuracy_train:.4f}    Original Test Acc: {accuracy_test_original:.4f}  Poisoned Test Acc: {accuracy_test_poisoned:.4f}\")\n",
    "        \n",
    "        if save_every_epoch:\n",
    "            torch.save(model.state_dict(), f\"{model_save_path}_epoch_{epoch:02d}.pt\")\n",
    "\n",
    "    print(\"Train Poisoned Classification Report\")\n",
    "    evaluate(model, train_poisoned_dataloader, print_classification_report=True)\n",
    "    print(\"Test Original Classification Report\")\n",
    "    evaluate(model, test_original_dataloader, print_classification_report=True)\n",
    "    print(\"Test Poisoned Classification Report\")\n",
    "    evaluate(model, test_poisoned_dataloader, print_classification_report=True)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{model_save_path}.pt\")\n",
    "    pd.DataFrame(\n",
    "        logs,\n",
    "        columns=(\"epoch\", \"loss\", \"accuracy_train\", \"accuracy_test_original\", \"accuracy_test_poisoned\")\n",
    "    ).to_csv(logs_save_path,  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spcs(model, dataloader, device, max_n=11, num_samples=100, nspc_factors=None):\n",
    "    model.eval()\n",
    "    y_true = []    \n",
    "    y_pred = np.empty((len(dataloader.dataset) * 2, max_n))\n",
    "    batch_size = dataloader.batch_size\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        y_true.append(targets)\n",
    "        y_true.append(targets)\n",
    "        noisy_inputs = inputs + 0.05 * torch.rand(size=inputs.shape, device=device)\n",
    "\n",
    "        for n in range(1, max_n + 1):\n",
    "            inputs_scaled = torch.clamp(torch.cat((inputs, noisy_inputs)) * n, min=0, max=1)\n",
    "            y_pred[i * batch_size * 2 : (i + 1) * batch_size * 2, n - 1] = (\n",
    "                torch.argmax(model(inputs_scaled), dim=1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "    y_true = torch.cat(y_true).cpu().numpy()\n",
    "    spcs = np.mean(y_pred == np.expand_dims(y_pred[:, 0], axis=1), axis=1)\n",
    "    could_compute_nspcs = True\n",
    "    \n",
    "    if nspc_factors is None:\n",
    "        nspc_factors = {class_: 0 for class_ in dataloader.dataset.classes}\n",
    "\n",
    "        for class_ in nspc_factors:\n",
    "            spcs_ = spcs[y_pred[:, 0] == class_][:num_samples]\n",
    "            mean_ = spcs_.mean()\n",
    "            std_ = spcs_.std()\n",
    "\n",
    "            if std_ == 0:\n",
    "                nspc_factors = {class_: 0 for class_ in dataloader.dataset.classes}\n",
    "                could_compute_nspcs = False\n",
    "                break\n",
    "            \n",
    "            nspc_factors[class_] = mean_ / std_\n",
    "    \n",
    "    nspcs = spcs - np.array([nspc_factors[y] for y in y_true])\n",
    "    mask = y_pred[:, 0] == y_true\n",
    "    spcs = spcs[mask]\n",
    "    nspcs = nspcs[mask]\n",
    "    return spcs, nspcs, nspc_factors, could_compute_nspcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUROC(model, test_original_dataloader, test_poisoned_dataloader, device):\n",
    "    original_spcs, original_nspcs, nspc_factors, could_compute_nspcs = get_spcs(model, test_original_dataloader, device)\n",
    "    poisoned_spcs, poisoned_nspcs, _, _ = get_spcs(model, test_poisoned_dataloader, device, nspc_factors=nspc_factors)\n",
    "\n",
    "    y_true_spcs = [1] * len(poisoned_spcs) + [0] * len(original_spcs)\n",
    "    y_pred_spcs = list(poisoned_spcs) + list(original_spcs)\n",
    "    fpr_spcs, tpr_spcs, _ = metrics.roc_curve(y_true_spcs, y_pred_spcs, pos_label=1)\n",
    "    auc_spcs = metrics.roc_auc_score(y_true_spcs, y_pred_spcs)\n",
    "\n",
    "    y_true_nspcs = [1] * len(poisoned_nspcs) + [0] * len(original_nspcs)\n",
    "    y_pred_nspcs = list(poisoned_nspcs) + list(original_nspcs)\n",
    "    fpr_nspcs, tpr_nspcs, _ = metrics.roc_curve(y_true_nspcs, y_pred_nspcs, pos_label=1)\n",
    "    auc_nspcs = metrics.roc_auc_score(y_true_nspcs, y_pred_nspcs)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    \n",
    "    axes[0].plot(fpr_spcs, tpr_spcs, label=f\"AUC: {auc_spcs:.3f}\")\n",
    "    axes[0].set_xlabel(\"False Positive Rate (FPR)\")\n",
    "    axes[0].set_ylabel(\"True Positive Rate (TPR)\")\n",
    "    axes[0].set_title(\"SPC ROC Curve\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    axes[1].plot(fpr_nspcs, tpr_nspcs, label=f\"AUC: {auc_nspcs:.3f}\")\n",
    "    axes[1].set_xlabel(\"False Positive Rate (FPR)\")\n",
    "    axes[1].set_ylabel(\"True Positive Rate (TPR)\")\n",
    "    axes[1].set_title(\"NSPC ROC Curve\")\n",
    "    axes[1].legend(loc=\"best\")\n",
    "\n",
    "    print(could_compute_nspcs)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.GTSRB(\n",
    "    root=\"./data\",\n",
    "    split=\"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=False\n",
    ")\n",
    "test_dataset = torchvision.datasets.GTSRB(\n",
    "    root=\"./data\",\n",
    "    split=\"test\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "pattern = torch.zeros((64, 64))\n",
    "pattern[-4:, -4:] = torch.rand((4, 4))\n",
    "\n",
    "weight = torch.zeros((64, 64))\n",
    "weight[-4:, -4:] = 1.0\n",
    "\n",
    "y_target = 0\n",
    "poison_rate = 5\n",
    "\n",
    "def preprocess(dataset):\n",
    "    data = []\n",
    "    targets = []\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        data.append(images.clone())\n",
    "        targets.append(labels.clone())\n",
    "\n",
    "    data = torch.cat(data)\n",
    "    targets = torch.cat(targets)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "train_data, train_targets = preprocess(train_dataset)\n",
    "test_data, test_targets = preprocess(test_dataset)\n",
    "\n",
    "(\n",
    "    train_poisoned_dataloader,\n",
    "    test_original_dataloader,\n",
    "    test_poisoned_dataloader\n",
    ") = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    train_targets=train_targets,\n",
    "    test_data=test_data,\n",
    "    test_targets=test_targets,\n",
    "    pattern=pattern,\n",
    "    weight=weight,\n",
    "    y_target=y_target,\n",
    "    poison_rate=poison_rate,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model_save_path = os.path.join(\"models\", f\"gtsrb_y_target_{y_target}_poison_rate_{poison_rate}\")\n",
    "logs_save_path = os.path.join(\"logs\", f\"gtsrb_y_target_{y_target}_poison_rate_{poison_rate}\")\n",
    "\n",
    "train(\n",
    "    train_poisoned_dataloader=train_poisoned_dataloader,\n",
    "    test_original_dataloader=test_original_dataloader,\n",
    "    test_poisoned_dataloader=test_poisoned_dataloader,\n",
    "    model=model,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    epochs=30,\n",
    "    model_save_path=model_save_path,\n",
    "    logs_save_path=logs_save_path,\n",
    "    save_every_epoch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_model()\n",
    "loaded_model.load_state_dict(torch.load(f\"{model_save_path}.pt\"))\n",
    "\n",
    "AUROC(loaded_model, test_original_dataloader, test_poisoned_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_confidence_scores(model, dataloader, max_n=11):\n",
    "    probs = [0 for _ in range(max_n)]\n",
    "    totals = [0 for _ in range(max_n)]\n",
    "\n",
    "    for inputs, _ in dataloader:\n",
    "        y_preds = model(inputs).argmax(dim=1)\n",
    "\n",
    "        for n in range(1, max_n + 1):\n",
    "            inputs_scaled = torch.clamp(inputs * n, min=0, max=1)\n",
    "            probs[n - 1] += F.softmax(model(inputs_scaled), dim=1)[torch.arange(inputs_scaled.shape[0]), y_preds].sum().item()\n",
    "            totals[n - 1] += inputs_scaled.shape[0]\n",
    "    \n",
    "    return [p / t for p, t in zip(probs, totals)]\n",
    "\n",
    "\n",
    "benign_confidence_scores = get_confidence_scores(loaded_model, test_original_dataloader)\n",
    "poisoned_confidence_scores = get_confidence_scores(loaded_model, test_poisoned_dataloader)\n",
    "\n",
    "plt.plot(range(1, 12), benign_confidence_scores, color=\"red\", marker=\"+\", label=\"Benign Samples\")\n",
    "plt.plot(range(1, 12), poisoned_confidence_scores, color=\"blue\", marker=\"^\", label=\"Poisoned Samples\")\n",
    "plt.xlabel(\"Multiplication Times\", fontsize=15)\n",
    "plt.ylabel(\"Average Confidence\", fontsize=15)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(f\"GTSRB, Poison Rate: {poison_rate}%, Target Label: {y_target}\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/gtsrb_y_target_{y_target}_poison_rate_{poison_rate}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
